---
title: "Diabetes Health Indicators Analysis"
author: "Zhao Qixian | Mehta Rishika | Tian Yumeng | Low Jo Yi, Nicole | Lu ShanShan" 
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    code_folding: show
    theme: united
---


```{r setup, include=FALSE}
# Global options for the document are set here.
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE,
  fig.path = "figures/"   # Save images externally in the figures folder
)
```

# Introduction

This document analyzes the diabetes health indicators from the BRFSS2015 dataset. We explore the data’s structure, conduct exploratory data analysis (EDA), test associations through various statistical methods, build predictive models using ordinal logistic regression and decision trees, and compare model performance.

# Project Objectives and Research Questions

### Objectives
- Conduct comprehensive EDA to identify statistically significant relationships between health indicators and diabetes status.
- Apply both statistical tests and machine learning models to predict and explain diabetes risk.
- Compare the influence of demographic, lifestyle, and physiological variables on diabetes.

### Research Questions
1. Which health indicators (e.g., blood pressure, cholesterol) are strongly associated with diabetes status?
2. How do factors such as age, BMI, and physical activity differ across diabetes groups?
3. Can ordinal regression and decision tree models accurately classify diabetes status?
4. What improvements are observed when including additional socioeconomic indicators in the prediction models?

---

# Install and Load Required Packages

We define a helper function to install (if needed) and load all required packages.

```{r install-packages, echo=TRUE}
install_and_load_packages <- function(packages) {
  output <- ""
  for (pkg in packages) {
    if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
      output <- paste0(output, "Installing: ", pkg, "...\n")
      suppressMessages(suppressWarnings(
        install.packages(pkg, dependencies = TRUE, repos = "https://cran.rstudio.com/")
      ))
      output <- paste0(output, "✅ Successfully installed: ", pkg, "\n")
    }
    suppressMessages(suppressWarnings(library(pkg, character.only = TRUE)))
    output <- paste0(output, "✅ Loaded: ", pkg, "\n")
  }
  cat(output)
}

packages <- c("dplyr", "ggplot2", "tidyr", "corrplot", "caret", "MASS",
              "randomForest", "glmnet", "pROC", "e1071", "car", "rmarkdown",
              "knitr", "kableExtra", "scales", "gridExtra", "reshape2",
              "rpart", "rpart.plot", "DescTools", "vcd", "brant", "VGAM")
install_and_load_packages(packages)
```

*This chunk ensures all required libraries are installed and loaded.*

---

# Data Loading and Initial Exploration

### Load the Data

```{r load-data}
# Load the data – make sure the CSV file is in your working directory.
diabetes_data <- read.csv("data/diabetes_012_health_indicators_BRFSS2015.csv", header = TRUE)

# Display the first few rows of the dataset
head(diabetes_data)
```

*We load the BRFSS2015 data into the variable `diabetes_data` and preview its content.*

### Examine Data Structure and Unique Values

```{r explore-structure}
# Display the structure of the dataset
str(diabetes_data)

# Compute unique values for each variable
unique_values <- lapply(diabetes_data, unique)
unique_counts <- sapply(unique_values, length)

# Create a summary data frame of unique value counts per column
unique_summary <- data.frame(
  Column = names(unique_counts),
  Unique_Values = unique_counts,
  row.names = NULL
)
print(unique_summary)
```

*This code shows the structure of the data and summarizes the number of unique values for each column to help identify variable types.*

---

# Data Cleaning and Preprocessing

### Check for Duplicates and Missing Values

```{r data-cleaning}
# Check for duplicate rows
duplicate_count <- sum(duplicated(diabetes_data))
duplicate_percentage <- (duplicate_count / nrow(diabetes_data)) * 100
cat("Number of duplicates:", duplicate_count, "\n")
cat("Percentage of duplicates:", round(duplicate_percentage, 2), "%\n")

# Check for NA values in each column
na_counts <- colSums(is.na(diabetes_data))
na_percentages <- round((na_counts / nrow(diabetes_data)) * 100, 2)
null_summary <- data.frame(
  Column = names(diabetes_data),
  NA_Count = na_counts,
  NA_Percentage = na_percentages
)
if (sum(na_counts) > 0) {
  print(null_summary[null_summary$NA_Count > 0, ])
} else {
  cat("No null values found in the dataset.\n")
}
```

*We check the dataset for duplicate observations and missing values to assess data quality.*

---

# Exploratory Data Analysis (EDA)

### Data Preparation for Analysis

```{r data-prep-eda}
# Convert Diabetes_012 into a factor with descriptive labels.
diabetes_data$Diabetes_012 <- factor(diabetes_data$Diabetes_012,
                                     levels = c(0, 1, 2),
                                     labels = c("No Diabetes", "Prediabetes", "Diagnosed Diabetes"))
```

*The target variable, Diabetes_012, is converted to a factor with meaningful labels.*

### Define a Function for Categorical Plots

```{r plot-categorical}
# Function to plot frequency distributions for categorical variables.
plot_categorical <- function(data, var) {
  ggplot(data, aes(x = factor(.data[[var]]))) +
    geom_bar(fill = "steelblue") +
    labs(title = paste("Frequency Plot of", var),
         x = var, y = "Count") +
    theme_minimal()
}
```

*This helper function creates bar plots for any categorical variable in the dataset.*

### Summary Statistics and Visualizations

#### Diabetes Status Distribution

```{r diabetes-status-distribution}
# Create a barplot for Diabetes_012 distribution using base R.
counts <- table(diabetes_data$Diabetes_012)
bp <- barplot(counts,
              main = "Distribution of Diabetes Status",
              col = c("lightblue", "lightgreen", "lightcoral"),
              names.arg = levels(diabetes_data$Diabetes_012),
              ylab = "Frequency",
              xlab = "Diabetes Status",
              ylim = c(0, max(counts) * 1.2),
              yaxt = "n")
axis(2, at = seq(0, max(counts), by = 25000), labels = seq(0, max(counts), by = 25000))
text(bp, counts + 100, labels = counts, col = "black", cex = 0.7)
```

*This block produces a barplot to display the distribution of diabetes status in the dataset.*

#### High Blood Pressure, High Cholesterol, and Cholesterol Check

```{r categorical-plots}
# Plot the distribution of several categorical variables.
plot_categorical(diabetes_data, "HighBP")
plot_categorical(diabetes_data, "HighChol")
plot_categorical(diabetes_data, "CholCheck")
```

*These plots show the frequencies for high blood pressure, high cholesterol, and whether a cholesterol check was performed.*

#### BMI Analysis

```{r bmi-analysis}
# Histogram and boxplot for BMI
BMI <- diabetes_data$BMI
hist(BMI, breaks = 50, main = "Histogram of BMI", xlab = "BMI")
boxplot(BMI, main = "Boxplot of BMI")
summary(BMI)

# Log transformation of BMI to reduce skewness
log_BMI <- log(BMI + 1)  # Adding 1 to avoid issues with zero values
hist(log_BMI, breaks = 40, main = "Histogram of log(BMI)", xlab = "log(BMI)")
boxplot(log_BMI, main = "Boxplot of log(BMI)")
```

*BMI is examined via a histogram and boxplot. A log transformation is applied to reduce right skewness.*

#### Other Lifestyle and Health Indicators

```{r lifestyle-eda}
# Plot distributions for various lifestyle/health factors using the helper function.
plot_categorical(diabetes_data, "Smoker")
plot_categorical(diabetes_data, "Stroke")
plot_categorical(diabetes_data, "HeartDiseaseorAttack")
plot_categorical(diabetes_data, "PhysActivity")
plot_categorical(diabetes_data, "Fruits")
plot_categorical(diabetes_data, "Veggies")
plot_categorical(diabetes_data, "HvyAlcoholConsump")
plot_categorical(diabetes_data, "AnyHealthcare")
plot_categorical(diabetes_data, "NoDocbcCost")
```

*These plots provide an overview of the distributions for lifestyle and health factors in the dataset.*

#### General Health, Mental Health & Physical Health

```{r health-rating}
# General Health Rating distribution with custom colors.
colors_genhlth <- c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854")
counts_gh <- table(diabetes_data$GenHlth)
bp_genhlth <- barplot(counts_gh,
                      col = colors_genhlth,
                      main = "Distribution of General Health Ratings",
                      xlab = "General Health Rating",
                      ylab = "Frequency",
                      ylim = c(0, max(counts_gh) * 1.2),
                      names.arg = c("Excellent", "Very Good", "Good", "Fair", "Poor"))
text(bp_genhlth, counts_gh + 0.02 * max(counts_gh), labels = counts_gh, pos = 3, cex = 0.8)

# Distribution of Mentally Unhealthy Days (log scale)
hist_data <- hist(diabetes_data$MentHlth, breaks = seq(0, 30, by = 2), plot = FALSE)
bp_ment <- barplot(log10(hist_data$counts + 1),
                   names.arg = hist_data$mids,
                   col = "lightblue",
                   main = "Distribution of Bad Mental Health Days (Log Scale)",
                   xlab = "Days", ylab = "Log10(Frequency)",
                   ylim = c(0, log10(max(hist_data$counts + 1)) + 1))
text(bp_ment, log10(hist_data$counts + 1), labels = hist_data$counts, pos = 3, cex = 0.8)
```

*The above code visualizes self-rated general health and the number of mentally unhealthy days (transformed to log scale).*

#### Age Distribution

```{r age-distribution}
library(gridExtra)

# Histogram and boxplot for Age distribution using ggplot2.
hist_plot <- ggplot(diabetes_data, aes(x = Age)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black") +
  labs(title = "Distribution of Age",
       x = "Age Group", y = "Frequency") +
  scale_x_continuous(breaks = seq(1, 13, by = 1),
                     labels = c("18-24", "25-29", "30-34", "35-39", "40-44",
                                "45-49", "50-54", "55-59", "60-64", "65-69",
                                "70-74", "75-79", "80+")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

box_plot <- ggplot(diabetes_data, aes(y = Age)) +
  geom_boxplot(fill = "steelblue") +
  labs(title = "Boxplot of Age", y = "Age Group") +
  scale_y_continuous(breaks = seq(1, 13, by = 1),
                     labels = c("18-24", "25-29", "30-34", "35-39", "40-44",
                                "45-49", "50-54", "55-59", "60-64", "65-69",
                                "70-74", "75-79", "80+")) +
  theme_minimal()

grid.arrange(hist_plot, box_plot, ncol = 2)
```

*We examine the age distribution using both a histogram and a boxplot for a detailed view.*

#### Education and Income

```{r education-income}
plot_categorical(diabetes_data, "Education")
plot_categorical(diabetes_data, "Income")
```

*These plots show the distribution of education levels and income levels in the dataset.*

---

# Associations Between Variables and Diabetes_012

### 1. Categorical Variables: Cramer's V Test

```{r cramers-v-test}
library(vcd)

# Select nominal variables for testing (excluding the target variable)
nominal_vars <- c("HighBP", "HighChol", "CholCheck", "Smoker", "Stroke",
                  "HeartDiseaseorAttack", "PhysActivity", "Fruits", "Veggies",
                  "HvyAlcoholConsump", "AnyHealthcare", "NoDocbcCost", "DiffWalk", "Sex")

# Function to calculate Cramer's V for two variables.
calc_cramersV <- function(var1, var2) {
  cont_table <- table(var1, var2)
  assoc_stats <- assocstats(cont_table)
  return(assoc_stats$cramer)
}

# Calculate Cramer's V for each nominal variable against Diabetes_012.
cramers_v_results <- data.frame(Variable = character(), CramersV = numeric(), stringsAsFactors = FALSE)
for (var in nominal_vars) {
  v_val <- calc_cramersV(diabetes_data$Diabetes_012, diabetes_data[[var]])
  cramers_v_results <- rbind(cramers_v_results, data.frame(Variable = var, CramersV = v_val))
}
print(cramers_v_results)
```

*This chunk computes Cramer’s V for each nominal variable versus diabetes status to evaluate the strength of association.*

### 2. Ordinal Variables: Kruskal-Wallis Test

```{r kruskal-ordinal}
# Define ordinal variables (as provided by their measurement scale)
ordinal_vars <- c("GenHlth", "Age", "Education", "Income")
kruskal_results <- data.frame(Variable = character(),
                              Kruskal_Statistic = numeric(),
                              P_Value = numeric(), stringsAsFactors = FALSE)
for (var in ordinal_vars) {
  test_result <- kruskal.test(diabetes_data[[var]] ~ diabetes_data$Diabetes_012)
  kruskal_results <- rbind(kruskal_results,
                           data.frame(Variable = var,
                                      Kruskal_Statistic = test_result$statistic,
                                      P_Value = test_result$p.value))
}
print(kruskal_results)
```

*We perform Kruskal-Wallis tests on ordinal variables to determine if their distributions differ across the diabetes status groups.*

### 3. Numerical Variables: Kruskal-Wallis Test and ANOVA

```{r numerical-tests}
# Select numerical variables: MentHlth and PhysHlth
numerical_vars <- c("MentHlth", "PhysHlth")
num_test_results <- data.frame(Variable = character(),
                               K_Statistic = numeric(),
                               P_Value = numeric(),
                               stringsAsFactors = FALSE)
for (var in numerical_vars) {
  test_result <- kruskal.test(diabetes_data[[var]] ~ diabetes_data$Diabetes_012)
  num_test_results <- rbind(num_test_results,
                            data.frame(Variable = var,
                                       K_Statistic = test_result$statistic,
                                       P_Value = test_result$p.value))
}
print(num_test_results)

# ANOVA for log(BMI)
anova_model <- aov(log_BMI ~ Diabetes_012, data = diabetes_data)
summary(anova_model)
```

*We test if MentHlth and PhysHlth differ by diabetes status using the Kruskal-Wallis test and perform ANOVA on log-transformed BMI.*

---

# Statistical Analysis (Hypothesis Testing)

### 1. Chi-Square Test

```{r chi-square-test}
# Test association between Diabetes_012 and HighChol using Chi-Square.
table_highchol <- table(diabetes_data$Diabetes_012, diabetes_data$HighChol)
chisq_test <- chisq.test(table_highchol)
chisq_test
```

*This Chi-Square test evaluates whether there is an association between high cholesterol status and diabetes status.*

### 2. Kruskal-Wallis Rank Sum Test

```{r kruskal-single-var}
# Kruskal-Wallis test for Age vs Diabetes_012
kruskal_age <- kruskal.test(Age ~ Diabetes_012, data = diabetes_data)
kruskal_age

# Physical Health vs Diabetes_012 (with a boxplot)
ggplot(diabetes_data, aes(x = Diabetes_012, y = PhysHlth)) +
  geom_boxplot(fill = "steelblue") +
  labs(title = "Physical Health by Diabetes Status",
       x = "Diabetes Status", y = "Physically Unhealthy Days") +
  theme_minimal()

kruskal_phys <- kruskal.test(PhysHlth ~ Diabetes_012, data = diabetes_data)
kruskal_phys
```

*These tests determine whether age and physical health days differ significantly across diabetes status groups.*

### 3. One-Way ANOVA Test on log(BMI)

```{r oneway-anova}
fit <- aov(log_BMI ~ Diabetes_012, data = diabetes_data)
summary(fit)
library(DescTools)
EtaSq(fit)
```

*One-way ANOVA is used to assess if the mean log(BMI) differs across diabetes categories, and eta squared is computed for effect size.*

### 4. Proportional Test

```{r prop-test}
# Proportional test: Testing if the proportion of non-diabetics among those with HighBP equals 0.55.
n_non_diabetes <- sum(diabetes_data$Diabetes_012 == "No Diabetes")
x_non_diabetes_highBP <- sum(diabetes_data$HighBP == 1 & diabetes_data$Diabetes_012 == "No Diabetes")
prop_test <- prop.test(x_non_diabetes_highBP, n_non_diabetes, p = 0.55, conf.level = 0.95)
prop_test
```

*This test checks if the observed proportion of non-diabetic individuals with high blood pressure differs from an expected 55%.*

### 5. Wilcoxon Rank Sum Test

```{r wilcoxon-test}
# Filter data for "No Diabetes" and "Diagnosed Diabetes" groups
dia_vs_nodia <- subset(diabetes_data, Diabetes_012 %in% c("No Diabetes", "Diagnosed Diabetes"))
boxplot(MentHlth ~ Diabetes_012, data = dia_vs_nodia, main = "Mental Health Days by Diabetes Status")
wilcox_result <- wilcox.test(MentHlth ~ Diabetes_012, data = dia_vs_nodia, exact = FALSE)
wilcox_result
```

*The Wilcoxon Rank Sum test compares the distributions of mentally unhealthy days between non-diabetic and diabetic individuals.*

---

# Multi-Variable Analysis

### Ordinal Logistic Regression

```{r ordinal-logistic}
# Convert BMI into a categorical variable based on cut-points.
diabetes_data$BMIlevel <- cut(diabetes_data$BMI, 
                              breaks = c(-Inf, 18.5, 24.9, 29.9, Inf), 
                              labels = c("Underweight", "Healthy", "Overweight", "Obese"))
diabetes_data$BMIlevel <- as.factor(diabetes_data$BMIlevel)

# Create a data frame for the physiological factors.
physioFactors <- data.frame(
  bmiLevel = diabetes_data$BMIlevel,
  bpLevel = as.factor(diabetes_data$HighBP),
  cholLevel = as.factor(diabetes_data$HighChol),
  diabeteStatus = diabetes_data$Diabetes_012
)

# Fit the Proportional Odds Model (Ordinal Logistic Regression)
model_polr <- polr(diabeteStatus ~ bpLevel + cholLevel + bmiLevel, data = physioFactors, Hess = TRUE)
summary(model_polr)

# Check proportional odds assumption using the Brant test.
brant(model_polr)

# Fit a Partial Proportional Odds Model allowing some predictors to vary.
model_ppo <- vglm(diabeteStatus ~ bpLevel * cholLevel * bmiLevel,
                  family = cumulative(parallel = FALSE ~ bpLevel + cholLevel),
                  data = physioFactors)
summary(model_ppo)
anova(model_ppo, type = "III")
```

*We first convert BMI into a factor and then build an ordinal logistic regression model. Since the Brant test may indicate violations in the proportional odds assumption, a partial proportional odds model is also fitted.*

### Nested Multivariable Model Comparison

```{r nested-models}
# Prepare a new data frame for modeling with proper ordering.
model_data <- diabetes_data %>%
  mutate(
    Diabetes_012 = factor(Diabetes_012, ordered = TRUE),
    Income = ordered(Income, levels = sort(unique(Income))),
    Education = ordered(Education, levels = sort(unique(Education))),
    AnyHealthcare = factor(AnyHealthcare),
    NoDocbcCost = factor(NoDocbcCost)
  )

# Fit core and extended ordinal regression models.
model_core <- polr(Diabetes_012 ~ Income + Education, data = model_data, Hess = TRUE)
model_extended <- polr(Diabetes_012 ~ Income + Education + AnyHealthcare + NoDocbcCost,
                       data = model_data, Hess = TRUE)

# Define a function for a likelihood ratio test between two polr models.
lr_test_polr <- function(model1, model2,
                         model1_name = "Income + Education",
                         model2_name = "Income + Education + AnyHealthcare + NoDocbcCost",
                         response_name = "Diabetes_012") {
  if (model1$nobs != model2$nobs)
    stop("Models must have the same number of observations.")
  nobs <- model1$nobs
  dev1 <- model1$deviance
  dev2 <- model2$deviance
  npar1 <- length(coef(model1)) + length(model1$zeta)
  npar2 <- length(coef(model2)) + length(model2$zeta)
  lr_stat <- dev1 - dev2
  df_diff <- npar2 - npar1
  p_val <- pchisq(lr_stat, df_diff, lower.tail = FALSE)
  
  cat("Likelihood ratio test between models:\n")
  cat("Model 1 (", model1_name, "): Residual deviance =", dev1, "\n")
  cat("Model 2 (", model2_name, "): Residual deviance =", dev2, "\n")
  cat("LR Statistic =", lr_stat, "with", df_diff, "degrees of freedom\n")
  cat("P-value =", p_val, "\n")
  invisible(list(lr_stat = lr_stat, df_diff = df_diff, p_value = p_val))
}

# Perform the likelihood ratio test.
lr_test_result <- lr_test_polr(model_core, model_extended)

# Display summaries of both models.
summary(model_core)
summary(model_extended)

# Plot density of predicted probabilities for Diagnosed Diabetes.
probs_core <- predict(model_core, type = "probs")
probs_ext <- predict(model_extended, type = "probs")
core_prob <- probs_core[, "Diagnosed Diabetes"]
ext_prob <- probs_ext[, "Diagnosed Diabetes"]
df_core <- data.frame(Probability = core_prob, Model = "Core")
df_ext <- data.frame(Probability = ext_prob, Model = "Extended")
df_plot <- rbind(df_core, df_ext)

ggplot(df_plot, aes(x = Probability, fill = Model)) +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c("Core" = "#FF9999", "Extended" = "#99CC99")) +
  labs(title = "Density Plot of Predicted Probabilities for Diagnosed Diabetes",
       x = "Predicted Probability", y = "Density") +
  theme_minimal()
```

*Two ordinal regression models (core and extended) are fitted and compared using a likelihood ratio test. The predicted probabilities for the “Diagnosed Diabetes” category are visualized to assess model differences.*

---

# Machine Learning

### Decision Tree for Diabetes Prediction

```{r decision-tree-diabetes}
# Data preparation: Convert necessary predictors to factor and create log-transformed BMI.
diabetes_data_ml <- diabetes_data %>%
  mutate(
    Diabetes_012 = factor(Diabetes_012, levels = c("No Diabetes", "Prediabetes", "Diagnosed Diabetes")),
    log_BMI = log(BMI + 1),
    across(c(HighBP, HighChol, CholCheck, Smoker, Stroke, HeartDiseaseorAttack,
             PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare,
             NoDocbcCost, DiffWalk, Sex), as.factor)
  )

# Sample a subset for faster execution.
set.seed(123)
data_sample <- sample_n(diabetes_data_ml, 10000)

# Split the sample data into training (70%) and test sets.
set.seed(123)
train_index <- createDataPartition(data_sample$Diabetes_012, p = 0.7, list = FALSE)
train_data <- data_sample[train_index, ]
test_data <- data_sample[-train_index, ]

# Build a decision tree model using rpart.
tree_model <- rpart(Diabetes_012 ~ HighBP + HighChol + log_BMI + Smoker + Stroke + 
                      HeartDiseaseorAttack + PhysActivity + Fruits + Veggies + 
                      HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + 
                      MentHlth + PhysHlth + DiffWalk + Sex + Age + Education + Income,
                    data = train_data,
                    method = "class",
                    control = rpart.control(minsplit = 20, minbucket = 10, cp = 0.001, maxdepth = 5))

# Visualize the decision tree.
rpart.plot(tree_model, type = 4, extra = 104, box.palette = "GnBu",
           branch.lty = 3, shadow.col = "gray", nn = TRUE,
           main = "Decision Tree for Diabetes Prediction")

# Print and plot the complexity parameter (cp) table.
printcp(tree_model)
plotcp(tree_model)

# Make predictions on test data.
predictions <- predict(tree_model, test_data, type = "class")
confusion_matrix <- confusionMatrix(predictions, test_data$Diabetes_012)
print(confusion_matrix)

# Compute and plot feature importance.
importance <- varImp(tree_model, scale = TRUE)
importance <- importance[order(-importance$Overall), , drop = FALSE]
importance_df <- data.frame(Feature = rownames(importance), Importance = importance$Overall)
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.7) +
  geom_text(aes(label = round(Importance, 2)), hjust = -0.2, size = 3.5) +
  coord_flip() +
  labs(title = "Feature Importance in Diabetes Prediction", 
       x = "Features", y = "Importance Score") +
  theme_minimal() +
  expand_limits(y = max(importance_df$Importance) * 1.2)
```

*This section builds a decision tree model to predict diabetes status. The tree is visualized, its performance is evaluated with a confusion matrix, and predictor importance is examined.*

### Decision Tree for Prediabetes Prediction (with Upsampling)

```{r decision-tree-prediabetes}
# Upsample prediabetes cases in the training set to address class imbalance.
train_data_upsampled <- upSample(x = train_data[, !(names(train_data) %in% "Diabetes_012")],
                                 y = train_data$Diabetes_012,
                                 yname = "Diabetes_012") %>% as.data.frame()

# Build the decision tree model focusing on prediabetes.
tree_model_prediabetes <- rpart(Diabetes_012 ~ .,
                                data = train_data_upsampled,
                                method = "class",
                                parms = list(split = "information"),
                                control = rpart.control(minsplit = 20, minbucket = 7,
                                                        cp = 0.0005, maxdepth = 6,
                                                        loss = matrix(c(0, 1, 1,
                                                                        1, 0, 1,
                                                                        1, 1, 0), nrow = 3)))
# Visualize the tree with a customized palette to highlight prediabetes.
rpart.plot(tree_model_prediabetes, type = 4, extra = 104,
           box.palette = list("No Diabetes" = "lightgreen", 
                              "Prediabetes" = "gold", 
                              "Diagnosed Diabetes" = "salmon"),
           main = "Decision Tree with Prediabetes Focus")

# Evaluate the prediabetes model.
predictions_prediabetes <- predict(tree_model_prediabetes, test_data, type = "class")
conf_matrix_prediabetes <- confusionMatrix(predictions_prediabetes, test_data$Diabetes_012)
print(conf_matrix_prediabetes$byClass["Class: Prediabetes", ])

# Calculate and visualize feature importance for the prediabetes model.
importance_prediabetes <- varImp(tree_model_prediabetes, scale = TRUE)
importance_prediabetes <- importance_prediabetes[order(-importance_prediabetes$Overall), , drop = FALSE]
ggplot(data.frame(Feature = rownames(importance_prediabetes), Importance = importance_prediabetes$Overall),
       aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "gold") +
  geom_text(aes(label = round(Importance, 2)), hjust = -0.2, size = 3.5) +
  coord_flip() +
  labs(title = "Feature Importance for Prediabetes Prediction",
       x = "Features", y = "Importance Score") +
  theme_minimal() +
  expand_limits(y = max(importance_prediabetes$Overall) * 1.2)
```

*Here we address class imbalance by upsampling prediabetes cases, build a decision tree specialized for prediabetes prediction, and evaluate the model with a focus on key predictor importance.*

---

# Conclusion

This consolidated analysis has:

- **Explored** the structure and unique features of the dataset.
- **Visualized** key health indicators and their distributions.
- **Tested** associations between diabetes status and various categorical, ordinal, and numerical variables.
- **Built** both ordinal regression and decision tree models for predicting diabetes status.
- **Compared** model performance and identified important predictors.

By combining statistical tests with machine learning approaches, we gain a deeper understanding of the factors driving diabetes risk and improve our predictive capabilities.
```
